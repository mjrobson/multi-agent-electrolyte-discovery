{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf1ad88",
   "metadata": {},
   "source": [
    "# Prepare Paper Databases\n",
    "\n",
    "## 1. Extract Papers from pdf \n",
    "\n",
    "### Workflow Steps\n",
    "\n",
    "1. **Input Preparation**\n",
    "   - Place all PDFs in a dedicated folder (e.g., `/inputs/papers_pdf`)\n",
    "   - Ensure files have `.pdf` extensions\n",
    "   - ⚠️ Note: Scanned/image-based PDFs will not process correctly \n",
    "\n",
    "Set paths in the configuration cell:\n",
    "   ```python\n",
    "   PDF_DIR = \"./inputs/papers_pdf\"  # Input PDFs\n",
    "   OUTPUT_DIR = \"./inputs/papers_text\"  # Clean text output\n",
    "   ```\n",
    "2. Run the processing cell to execute:\n",
    "   ```python\n",
    "   process_pdf_batch(PDF_DIR, OUTPUT_DIR)\n",
    "   ```\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff87c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PDF_DIR = \"./inputs/papers_pdf\" \n",
    "OUTPUT_DIR = \"./inputs/papers_text\"\n",
    "\n",
    "# Import processing function\n",
    "from model_resources.functions.extraction import process_pdf_batch\n",
    "\n",
    "# Execute pipeline\n",
    "process_pdf_batch(PDF_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ad20e",
   "metadata": {},
   "source": [
    "# 2. Set up API keys for this session\n",
    "\n",
    "Enter your OpenAI API key in the field provided below. This will store the key as an environment variable (OPENAI_API_KEY) for use during this notebook session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6379cb",
   "metadata": {},
   "source": [
    "## 3. Summarize Extracted Paper Texts Using GPT-4\n",
    "\n",
    "This step processes all extracted paper text files and summarizes them using GPT-4 via the OpenAI API.  \n",
    "Using the default prompt, the summarization framework extracts structured information relevant to deep eutectic electrolyte research, such as:\n",
    "- Electrolyte composition  \n",
    "- Cathode composition  \n",
    "- Electrochemical performance metrics  \n",
    "- Scientific rationale for composition choice\n",
    "\n",
    "Summaries are saved as `.txt` files in a specified output folder.  \n",
    "The prompt used for summarization is stored in `./model_resources/prompts/summarize.txt` for easy editing and customization.\n",
    "\n",
    "> -------------------------------------          \n",
    "> ⚠️ **Warning**:\n",
    ">  \n",
    "> Submitting large numbers of academic papers for summarization may incur **significant API costs** due to the high token count of full papers.\n",
    ">  \n",
    "> Please ensure:\n",
    "> - You are comfortable sending these documents to OpenAI’s servers.\n",
    "> - You understand the potential cost based on the number and length of the papers.\n",
    "> - If needed, consider using your **own local language model** or an **API cost monitor** during large batch processing.\n",
    "> ---------------------------------------         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_resources.functions.summarization import summarize_papers_with_gpt4\n",
    "\n",
    "# Configuration\n",
    "SOURCE_DIR = \"./inputs/papers_text\"\n",
    "SUMMARY_OUTPUT_DIR = \"./inputs/summaries\"\n",
    "\n",
    "# Run summarization\n",
    "summarize_papers_with_gpt4(SOURCE_DIR, SUMMARY_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860760db",
   "metadata": {},
   "source": [
    "## 3. Store Extracted Papers and Summaries as Vector Databases\n",
    "\n",
    "The `create_vector_db` function converts the extracted documents into embeddings for downstream retrieval.\n",
    "\n",
    "- The paper database is split into overlapping token-based chunks to preserve contextual granularity during retrieval.\n",
    "\n",
    "- The summary database stores entire summaries without splitting, as they are already concise.\n",
    "\n",
    "These vector stores are saved in the `model_databases/` directory and will later be used by the multi-agent system for information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d108cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_resources.functions.vector_db import create_vector_db\n",
    "\n",
    "# Create the paper database (with token splitting)\n",
    "\n",
    "PAPER_PERSIST_DIR = \"./model_databases/paperstore\"\n",
    "SUMMARY_PERSIST_DIR = \"./model_databases/summarystore\"\n",
    "\n",
    "# Create Paper Database\n",
    "create_vector_db(OUTPUT_DIR,PAPER_PERSIST_DIR, split_tokens=True)\n",
    "\n",
    "#Create Summary Databse\n",
    "create_vector_db(SUMMARY_OUTPUT_DIR,SUMMARY_PERSIST_DIR, split_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electrolyte-discovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
